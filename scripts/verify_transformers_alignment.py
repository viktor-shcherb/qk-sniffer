#!/usr/bin/env python3
from __future__ import annotations

import argparse
import ast
import re
import subprocess
import sys
import tempfile
import textwrap
from pathlib import Path


BANNER_PATTERNS = (
    re.compile(r"ðŸš¨"),
    re.compile(r"automatically generated from src/transformers/models/"),
    re.compile(r"Do NOT edit this file manually"),
    re.compile(r"file from the modular"),
    re.compile(r"modular_.* directly"),
)


def run(cmd: list[str]) -> subprocess.CompletedProcess[str]:
    return subprocess.run(cmd, check=False, text=True, capture_output=True)


def transformers_models_root(venv_python: Path) -> Path:
    proc = run(
        [
            str(venv_python),
            "-c",
            (
                "import pathlib, transformers;"
                "print(pathlib.Path(transformers.__file__).resolve().parent / 'models')"
            ),
        ]
    )
    if proc.returncode != 0:
        raise RuntimeError(f"Failed to resolve transformers path via {venv_python}:\n{proc.stderr}")
    return Path(proc.stdout.strip())


def canonicalize_imports(lines: list[str], model: str) -> list[str]:
    out: list[str] = []
    for line in lines:
        line = re.sub(r"^(\s*)from \.\.\. import ", r"\1from transformers import ", line)
        line = re.sub(r"^(\s*)from \.\. import ", r"\1from transformers import ", line)
        line = re.sub(r"^(\s*)from \.\.\.([\w\.]+) import ", r"\1from transformers.\2 import ", line)
        line = re.sub(r"^(\s*)from \.\.([\w\.]+) import ", r"\1from transformers.models.\2 import ", line)
        line = re.sub(r"^(\s*)from \.([\w\.]+) import ", fr"\1from transformers.models.{model}.\2 import ", line)
        out.append(line)
    return out


def drop_banner(lines: list[str]) -> list[str]:
    return [line for line in lines if not any(pattern.search(line) for pattern in BANNER_PATTERNS)]


def drop_sniffer_import_block(lines: list[str]) -> list[str]:
    out: list[str] = []
    i = 0
    n = len(lines)

    while i < n:
        if lines[i].startswith("try:") and "sniffer" in "\n".join(lines[i : min(i + 12, n)]):
            i += 1
            while i < n:
                line = lines[i]
                if line.startswith("except "):
                    i += 1
                    while i < n and (lines[i].strip() == "" or lines[i].startswith((" ", "\t"))):
                        i += 1
                    continue
                if line.strip() == "":
                    i += 1
                    continue
                if not line.startswith((" ", "\t")):
                    break
                i += 1
            continue
        out.append(lines[i])
        i += 1

    return out


def drop_sniffer_forward_blocks(lines: list[str]) -> list[str]:
    out: list[str] = []
    i = 0
    n = len(lines)

    while i < n:
        line = lines[i]
        if re.match(r"^\s*sniffer = get_active_sniffer\(\)\s*$", line):
            i += 1
            while i < n and not re.match(r"^\s*cos,\s*sin\s*=\s*position_embeddings\s*$", lines[i]):
                i += 1
            continue

        if re.match(r"^\s*if sniffer is not None and not capture_pre_rope:\s*$", line):
            indent = len(line) - len(line.lstrip())
            i += 1
            while i < n:
                cur = lines[i]
                if cur.strip() == "":
                    i += 1
                    continue
                cur_indent = len(cur) - len(cur.lstrip())
                if cur_indent <= indent:
                    break
                i += 1
            continue

        out.append(line)
        i += 1

    return out


def collapse_blank_lines(lines: list[str]) -> list[str]:
    out: list[str] = []
    previous_blank = False
    for line in lines:
        is_blank = line.strip() == ""
        if is_blank and previous_blank:
            continue
        out.append(line.rstrip())
        previous_blank = is_blank
    return out


def normalize_modeling(path: Path, model: str, side: str) -> str:
    lines = path.read_text(encoding="utf-8").splitlines()
    lines = drop_banner(lines)
    lines = canonicalize_imports(lines, model)

    if side == "local":
        lines = drop_sniffer_import_block(lines)
        lines = drop_sniffer_forward_blocks(lines)

    lines = collapse_blank_lines(lines)
    return "\n".join(lines).rstrip() + "\n"


def extract_function_source(module_path: Path, *, class_name: str | None, function_name: str) -> str:
    source = module_path.read_text(encoding="utf-8")
    tree = ast.parse(source)
    lines = source.splitlines()

    if class_name is None:
        for node in tree.body:
            if isinstance(node, ast.FunctionDef) and node.name == function_name:
                return "\n".join(lines[node.lineno - 1 : node.end_lineno]) + "\n"
    else:
        for node in tree.body:
            if isinstance(node, ast.ClassDef) and node.name == class_name:
                for child in node.body:
                    if isinstance(child, ast.FunctionDef) and child.name == function_name:
                        return "\n".join(lines[child.lineno - 1 : child.end_lineno]) + "\n"

    raise RuntimeError(f"Function {function_name} not found in {module_path}")


def normalize_mllama_forward(source: str, side: str) -> str:
    lines = textwrap.dedent(source).splitlines()
    lines = [line for line in lines if not line.strip().startswith("@")]

    if side == "local":
        lines = [line.replace("_orig.", "") for line in lines]
        lines = [
            re.sub(r"^def _sniffer_mllama_text_self_attention_forward\(", "def forward(", line)
            for line in lines
        ]
        lines = drop_sniffer_forward_blocks(lines)

    lines = collapse_blank_lines(lines)
    return "\n".join(lines).rstrip() + "\n"


def run_diff(left: Path, right: Path) -> tuple[bool, str]:
    proc = run(["diff", "-u", str(left), str(right)])
    return proc.returncode == 0, proc.stdout


def discover_models(models_root: Path) -> list[str]:
    discovered: list[str] = []
    for child in sorted(models_root.iterdir()):
        if not child.is_dir():
            continue
        name = child.name
        if (child / f"modeling_{name}.py").exists():
            discovered.append(name)
    return discovered


def is_mllama_wrapper(local_file: Path) -> bool:
    text = local_file.read_text(encoding="utf-8")
    return "_sniffer_mllama_text_self_attention_forward" in text and "_orig" in text


def main() -> int:
    parser = argparse.ArgumentParser(description="Verify local modeling files align with venv transformers via diff.")
    parser.add_argument("--venv-python", default="venv/bin/python", help="Python binary for installed transformers.")
    parser.add_argument(
        "--models-root", default="models", help="Local models root containing <model>/modeling_<model>.py files."
    )
    parser.add_argument(
        "--models",
        nargs="*",
        help="Specific models to verify (default: auto-discover all local model folders with modeling_<model>.py).",
    )
    args = parser.parse_args()

    repo_root = Path.cwd()
    local_models_root = (repo_root / args.models_root).resolve()
    venv_python_arg = Path(args.venv_python).expanduser()
    venv_python = venv_python_arg if venv_python_arg.is_absolute() else (repo_root / venv_python_arg)
    upstream_models_root = transformers_models_root(venv_python)

    models = args.models or discover_models(local_models_root)
    if not models:
        print("No model files found to verify.")
        return 0

    failures = 0
    print(f"Using transformers models from: {upstream_models_root}")
    print(f"Checking models: {', '.join(models)}")

    with tempfile.TemporaryDirectory(prefix="verify-transformers-alignment-") as tmp:
        tmpdir = Path(tmp)

        for model in models:
            local_file = local_models_root / model / f"modeling_{model}.py"
            upstream_file = upstream_models_root / model / f"modeling_{model}.py"

            if not local_file.exists():
                print(f"[FAIL] {model}: local file missing: {local_file}")
                failures += 1
                continue
            if not upstream_file.exists():
                print(f"[FAIL] {model}: upstream file missing: {upstream_file}")
                failures += 1
                continue

            if model != "mllama":
                normalized_upstream = normalize_modeling(upstream_file, model=model, side="upstream")
                normalized_local = normalize_modeling(local_file, model=model, side="local")
            else:
                if is_mllama_wrapper(local_file):
                    upstream_forward = extract_function_source(
                        upstream_file, class_name="MllamaTextSelfAttention", function_name="forward"
                    )
                    local_forward = extract_function_source(
                        local_file, class_name=None, function_name="_sniffer_mllama_text_self_attention_forward"
                    )
                    normalized_upstream = normalize_mllama_forward(upstream_forward, side="upstream")
                    normalized_local = normalize_mllama_forward(local_forward, side="local")
                else:
                    normalized_upstream = normalize_modeling(upstream_file, model=model, side="upstream")
                    normalized_local = normalize_modeling(local_file, model=model, side="local")

            up_tmp = tmpdir / f"upstream_{model}.py"
            local_tmp = tmpdir / f"local_{model}.py"
            up_tmp.write_text(normalized_upstream, encoding="utf-8")
            local_tmp.write_text(normalized_local, encoding="utf-8")

            ok, diff_output = run_diff(up_tmp, local_tmp)
            if ok:
                print(f"[OK]   {model}")
            else:
                failures += 1
                print(f"[FAIL] {model}")
                print(diff_output)

    if failures:
        print(f"\nResult: {failures} model(s) have drift.")
        return 1

    print("\nResult: all checked models align with installed transformers (after removing expected sniffer patches).")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
