dataset:
  path: viktoroo/longbench-pro-128k-plus
  name: null
  split: test
  text_column: text
  id_column: id
  max_samples: null

model:
  name: HuggingFaceTB/SmolLM2-135M
  revision: main
  dtype: float16
  device_map: auto
  trust_remote_code: false

tokenizer:
  name: HuggingFaceTB/SmolLM2-135M
  max_length: 512
  padding: longest
  padding_side: right
  trust_remote_code: false

inference:
  batch_size: 8
  autocast_dtype: float16
  debug_logging: true

capture:
  capture_queries: true
  capture_keys: true
  layers: null
  heads: null
  head_sampling:
    count: 300
    seed: 0
  full_attention_only: true
  capture_pre_rope: false
  capture_token_strings: false
  min_bucket_size: 32
  sampler:
    type: uniform
    base_rate: 1.0

output:
  data_root: data/attention-plasticity
  readme_path: README.md
  hf_repo_id: viktoroo/test-sniffer-qk
  hf_branch: smollm2-135m-longbench-pro-128k-plus
  private: false
